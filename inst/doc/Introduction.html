<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Introduction to the multivarious Package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to the multivarious
Package</h1>



<div id="the-goal-unified-dimensionality-reduction" class="section level2">
<h2>The Goal: Unified Dimensionality Reduction</h2>
<p>Multivariate data analysis often involves reducing dimensionality or
transforming data using techniques like Principal Component Analysis
(PCA), Partial Least Squares (PLS), Contrastive PCA (cPCA), Nyström
approximation for Kernel PCA, or representing data in a specific basis
(e.g., Fourier, splines). While each method has unique mathematical
underpinnings, they share common operational needs:</p>
<ul>
<li>Fitting the model to training data.</li>
<li>Extracting key components (scores, loadings/coefficients).</li>
<li>Projecting <em>new</em> data points into the reduced/transformed
space.</li>
<li>Reconstructing approximations of the original data from the reduced
space.</li>
<li>Integrating these steps with pre-processing (like centering or
scaling).</li>
<li>Comparing or tuning models using cross-validation.</li>
</ul>
<p>Handling these tasks consistently across different algorithms can
lead to repetitive code and complex workflows. The
<strong><code>multivarious</code> package aims to simplify this by
providing a unified interface</strong> centered around the concept of a
<strong><code>bi_projector</code></strong>.</p>
</div>
<div id="the-bi_projector-a-two-way-map" class="section level2">
<h2>The <code>bi_projector</code>: A Two-Way Map</h2>
<p>The <code>bi_projector</code> class is the cornerstone of
<code>multivarious</code>. It represents a linear transformation (or an
approximation thereof) that provides a <strong>two-way
mapping</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Samples (Rows) ↔︎ Scores:</strong> Maps data points from the
original high-dimensional space to a lower-dimensional latent space
(scores), and potentially back.</li>
<li><strong>Variables (Columns) ↔︎ Components/Loadings:</strong> Maps
original variables to their representation in the latent space
(loadings/components), and potentially back.</li>
</ol>
<p>Think of it as encapsulating the core results of a dimensionality
reduction technique (like the U, S, V components of an SVD, or the
scores and loadings of PCA/PLS) along with any necessary pre-processing
information.</p>
<p>Crucially, many functions within <code>multivarious</code> (e.g.,
<code>pca()</code>, <code>pls()</code>, <code>cPCAplus()</code>,
<code>nystrom_approx()</code>, <code>regress()</code>) return objects
that inherit from <code>bi_projector</code>.</p>
</div>
<div id="key-actions-with-a-bi_projector" class="section level2">
<h2>Key Actions with a <code>bi_projector</code></h2>
<p>Because different methods return a <code>bi_projector</code>, you can
perform common tasks using a consistent set of verbs:</p>
<ul>
<li><code>scores(model)</code>: Get the scores (latent space
representation) of the <em>training</em> data.</li>
<li><code>coef(model)</code> or <code>loadings(model)</code>: Get the
loadings or coefficients mapping variables to components.</li>
<li><code>project(model, newdata)</code>: Project <em>new</em> samples
(rows of <code>newdata</code>) into the latent space defined by the
<code>model</code>.</li>
<li><code>reconstruct(model, ...)</code>: Reconstruct an approximation
of the original data from the latent space (either from training scores
or provided new scores/coefficients).</li>
<li><code>truncate(model, ncomp)</code>: Reduce the number of components
kept in the model.</li>
<li><code>summary(model)</code>: Get a concise summary of the model
dimensions.</li>
</ul>
<p>This consistent API simplifies writing generic analysis code and
makes it easier to swap between different dimensionality reduction
methods.</p>
</div>
<div id="example-pca-workflow" class="section level2">
<h2>Example: PCA Workflow</h2>
<p>Let’s demonstrate a typical workflow using PCA on the classic
<code>iris</code> dataset.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Load iris dataset and select numeric columns</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># 1. Define a pre-processor (center the data)</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>preproc <span class="ot">&lt;-</span> <span class="fu">center</span>()</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co"># 2. Fit PCA using svd_wrapper, keeping 3 components</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#    The pre-processor is applied internally.</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">pca</span>(X, <span class="at">ncomp =</span> <span class="dv">3</span>, <span class="at">preproc =</span> preproc)</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># The result &#39;fit&#39; is a bi_projector</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="fu">print</span>(fit)</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">#&gt; PCA object  -- derived from SVD</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co">#&gt; Data: 150 observations x 4 variables</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co">#&gt; Components retained: 3</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co">#&gt; Variance explained (per component):</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="co">#&gt;  1 2 3  92.95  5.33  1.72%  (cumulative:  92.95 98.28   100%)</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a><span class="co"># 3. Access results</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>iris_scores <span class="ot">&lt;-</span> <span class="fu">scores</span>(fit) <span class="co"># Scores of the centered training data (150 x 3)</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>iris_loadings <span class="ot">&lt;-</span> <span class="fu">loadings</span>(fit) <span class="co"># Loadings (4 x 3)</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Dimensions of Scores:&quot;</span>, <span class="fu">dim</span>(iris_scores), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a><span class="co">#&gt; Dimensions of Scores: 150 3</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Dimensions of Loadings:&quot;</span>, <span class="fu">dim</span>(iris_loadings), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a><span class="co">#&gt; Dimensions of Loadings:</span></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a><span class="co"># 4. Project new data</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="co"># Create some new iris-like samples (5 samples, 4 variables)</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a>new_iris_data <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">5</span> <span class="sc">*</span> <span class="dv">4</span>, <span class="at">mean =</span> <span class="fu">colMeans</span>(X), <span class="at">sd =</span> <span class="fu">apply</span>(X, <span class="dv">2</span>, sd)), </span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>                        <span class="at">nrow =</span> <span class="dv">5</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="co"># Project the new data into the PCA space defined by &#39;fit&#39;</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a><span class="co"># Pre-processing (centering using training data means) is applied automatically.</span></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a>projected_new_scores <span class="ot">&lt;-</span> <span class="fu">project</span>(fit, new_iris_data)</span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Dimensions of Projected New Data Scores:&quot;</span>, <span class="fu">dim</span>(projected_new_scores), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a><span class="co">#&gt; Dimensions of Projected New Data Scores: 5 3</span></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(projected_new_scores))</span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a><span class="co">#&gt;            [,1]       [,2]        [,3]</span></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="co">#&gt; [1,] -2.2172144  0.8590909 -0.44924532</span></span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a><span class="co">#&gt; [2,] -0.3270495 -0.5478369  0.07965279</span></span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a><span class="co">#&gt; [3,] -1.7602954  0.9106117 -0.52932939</span></span>
<span id="cb1-48"><a href="#cb1-48" tabindex="-1"></a><span class="co">#&gt; [4,]  0.2367242 -0.3204326 -0.50433574</span></span>
<span id="cb1-49"><a href="#cb1-49" tabindex="-1"></a><span class="co">#&gt; [5,] -1.1529598  0.5426518  0.85478044</span></span>
<span id="cb1-50"><a href="#cb1-50" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" tabindex="-1"></a><span class="co"># 5. Reconstruct approximated original data from scores</span></span>
<span id="cb1-52"><a href="#cb1-52" tabindex="-1"></a><span class="co"># Reconstruct the first few original samples</span></span>
<span id="cb1-53"><a href="#cb1-53" tabindex="-1"></a>reconstructed_X_approx <span class="ot">&lt;-</span> <span class="fu">reconstruct</span>(fit, <span class="at">comp=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) <span class="co"># uses scores(fit) by default</span></span>
<span id="cb1-54"><a href="#cb1-54" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Reconstructed Approximation of Original Data (first 5 rows):</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb1-55"><a href="#cb1-55" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-56"><a href="#cb1-56" tabindex="-1"></a><span class="co">#&gt; Reconstructed Approximation of Original Data (first 5 rows):</span></span>
<span id="cb1-57"><a href="#cb1-57" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(reconstructed_X_approx))</span>
<span id="cb1-58"><a href="#cb1-58" tabindex="-1"></a><span class="co">#&gt;          [,1]     [,2]     [,3]      [,4]</span></span>
<span id="cb1-59"><a href="#cb1-59" tabindex="-1"></a><span class="co">#&gt; [1,] 5.099286 3.500723 1.401086 0.1982949</span></span>
<span id="cb1-60"><a href="#cb1-60" tabindex="-1"></a><span class="co">#&gt; [2,] 4.868758 3.031661 1.447517 0.1253679</span></span>
<span id="cb1-61"><a href="#cb1-61" tabindex="-1"></a><span class="co">#&gt; [3,] 4.693700 3.206384 1.309582 0.1849507</span></span>
<span id="cb1-62"><a href="#cb1-62" tabindex="-1"></a><span class="co">#&gt; [4,] 4.623843 3.075837 1.463736 0.2569583</span></span>
<span id="cb1-63"><a href="#cb1-63" tabindex="-1"></a><span class="co">#&gt; [5,] 5.019326 3.580414 1.370606 0.2461680</span></span>
<span id="cb1-64"><a href="#cb1-64" tabindex="-1"></a><span class="co">#&gt; [6,] 5.407635 3.892262 1.688387 0.4182392</span></span>
<span id="cb1-65"><a href="#cb1-65" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(X)) <span class="co"># Original data for comparison</span></span>
<span id="cb1-67"><a href="#cb1-67" tabindex="-1"></a><span class="co">#&gt;      Sepal.Length Sepal.Width Petal.Length Petal.Width</span></span>
<span id="cb1-68"><a href="#cb1-68" tabindex="-1"></a><span class="co">#&gt; [1,]          5.1         3.5          1.4         0.2</span></span>
<span id="cb1-69"><a href="#cb1-69" tabindex="-1"></a><span class="co">#&gt; [2,]          4.9         3.0          1.4         0.2</span></span>
<span id="cb1-70"><a href="#cb1-70" tabindex="-1"></a><span class="co">#&gt; [3,]          4.7         3.2          1.3         0.2</span></span>
<span id="cb1-71"><a href="#cb1-71" tabindex="-1"></a><span class="co">#&gt; [4,]          4.6         3.1          1.5         0.2</span></span>
<span id="cb1-72"><a href="#cb1-72" tabindex="-1"></a><span class="co">#&gt; [5,]          5.0         3.6          1.4         0.2</span></span>
<span id="cb1-73"><a href="#cb1-73" tabindex="-1"></a><span class="co">#&gt; [6,]          5.4         3.9          1.7         0.4</span></span></code></pre></div>
<p>This example shows how fitting (<code>pca</code>), accessing results
(<code>scores</code>, <code>loadings</code>), and applying the model to
new data (<code>project</code>) follow a consistent pattern, regardless
of whether the underlying method was PCA, PLS, or another technique
returning a <code>bi_projector</code>.</p>
</div>
<div id="beyond-basic-projection-the-multivarious-ecosystem" class="section level2">
<h2>Beyond Basic Projection: The <code>multivarious</code>
Ecosystem</h2>
<p>The unified <code>bi_projector</code> interface enables several
powerful features within the package:</p>
<ul>
<li><strong>Pre-processing Pipelines:</strong> Define reusable
pre-processing steps (see <code>vignette(&quot;PreProcessing&quot;)</code>).</li>
<li><strong>Model Composition:</strong> Chain multiple
<code>bi_projector</code> steps together (e.g., pre-processing → PCA →
rotation) into a single composite projector (see
<code>vignette(&quot;Composing_Projectors&quot;)</code>).</li>
<li><strong>Cross-Validation:</strong> Easily perform cross-validation
to select hyperparameters (like the number of components) using helpers
that understand the <code>bi_projector</code> structure (see
<code>vignette(&quot;CrossValidation&quot;)</code>).</li>
</ul>
</div>
<div id="projecting-variables-project_vars" class="section level2">
<h2>Projecting Variables (<code>project_vars</code>)</h2>
<p>While <code>project()</code> operates on new samples (rows), the
<code>bi_projector</code> also supports projecting new
<em>variables</em> (columns) into the component space defined by the
model’s scores (U vectors in SVD terms). This is done using
<code>project_vars()</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Using the &#39;fit&#39; object from the PCA example above</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Create a new variable (column) with the same number of samples as original data</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>new_variable <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(X))</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># Project this new variable into the component space defined by the PCA scores (fit$s)</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co"># Result shows how the new variable relates to the principal components.</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>projected_variable_loadings <span class="ot">&lt;-</span> <span class="fu">project_vars</span>(fit, new_variable)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Projection of new variable onto components:&quot;</span>, projected_variable_loadings, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">#&gt; Projection of new variable onto components: 0.0003082567 -0.0004245081 -0.0003111904</span></span></code></pre></div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>The <code>multivarious</code> package provides a consistent and
extensible framework for common dimensionality reduction and related
linear transformation tasks. By leveraging the <code>bi_projector</code>
class, it offers a unified API for fitting models, projecting new data,
reconstruction, and accessing key model components. This simplifies
workflows, promotes code reuse, and facilitates integration with
pre-processing, model composition, and cross-validation tools within the
package ecosystem.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
